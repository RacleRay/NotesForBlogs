{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于fasttext的文本情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#=======================文本处理========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import fastText\n",
    "import re  #正则表达式\n",
    "from bs4 import BeautifulSoup  #html标签处理\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def review_to_wordlist(review):\n",
    "    '''\n",
    "    把IMDB的评论转成词序列\n",
    "    '''\n",
    "    # 去掉HTML标签，拿到内容\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    # 用正则表达式取出符合规范的部分\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    # 小写所有的词，并转成词list\n",
    "    words = review_text.lower().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用pandas读入训练和测试csv文件\n",
    "train = pd.read_csv(\n",
    "    'data/labeledTrainData.tsv', header=0, delimiter=\"\\t\", quoting=3)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\\\\"The Classic War of the Worlds\\\\\" by Timothy Hines is a very entertaining film that obviously goes to great effort and lengths to faithfully recreate H. G. Wells\\' classic book. Mr. Hines succeeds in doing so. I, and those who watched his film with me, appreciated the fact that it was not the standard, predictable Hollywood fare that comes out every year, e.g. the Spielberg version with Tom Cruise that had only the slightest resemblance to the book. Obviously, everyone looks for different things in a movie. Those who envision themselves as amateur \\\\\"critics\\\\\" look only to criticize everything they can. Others rate a movie on more important bases,like being entertained, which is why most people never agree with the \\\\\"critics\\\\\". We enjoyed the effort Mr. Hines put into being faithful to H.G. Wells\\' classic novel, and we found it to be very entertaining. This made it easy to overlook what the \\\\\"critics\\\\\" perceive to be its shortcomings.\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(train['review'])\n",
    "train_num = int(num / 5 * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(0, train_num):\n",
    "    train_data.append(\" \".join(review_to_wordlist(train['review'][i])))\n",
    "\n",
    "test_data = []\n",
    "for i in range(train_num, num):\n",
    "    test_data.append(\" \".join(review_to_wordlist(train['review'][i])))\n",
    "\n",
    "y_train = train['sentiment'][:train_num]\n",
    "y_test = list(train['sentiment'][train_num:])\n",
    "\n",
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#=======================生成文件========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_file(file, x, y):\n",
    "    \n",
    "    for i, line in enumerate(x):\n",
    "        outline = line + \"\\t__label__\" + str(y[i]) + \"\\n\"\n",
    "        file.write(outline)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "ftrain = open(\"data/sentiment_train.txt\", \"w\")\n",
    "ftest = open(\"data/sentiment_test.txt\", \"w\")\n",
    "\n",
    "to_file(ftrain, train_data, y_train)\n",
    "to_file(ftest, test_data, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#=======================训练预测========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import train_supervised\n",
    "\n",
    "model = train_supervised(\n",
    "    input=\"data/sentiment_train.txt\",\n",
    "    epoch=25,\n",
    "    lr=1.0,\n",
    "    wordNgrams=2,\n",
    "    verbose=2,\n",
    "    minCount=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t5000\n",
      "P@1\t0.890\n",
      "R@1\t0.890\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "# 导入文件预测\n",
    "print_results(*model.test(\"data/sentiment_test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__1',), array([1.00001001]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入句子预测\n",
    "model.predict(\n",
    "    'the creators of south park in their own film here this is a brilliant film with a huge entertainment factor if you like naked gun films and are not young and not too mature or serious on your humor you ll love this')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "IMPORTANT: Preprocessing data / enconding conventions\n",
    "In general it is important to properly preprocess your data. In particular our example scripts in the root folder do this.\n",
    "\n",
    "fastText assumes UTF-8 encoded text. All text must be unicode for Python2 and str for Python3. The passed text will be encoded as UTF-8 by pybind11 before passed to the fastText C++ library. This means it is important to use UTF-8 encoded text when building a model. On Unix-like systems you can convert text using iconv.\n",
    "\n",
    "fastText will tokenize (split text into pieces) based on the following ASCII characters (bytes). In particular, it is not aware of UTF-8 whitespace. We advice the user to convert UTF-8 whitespace / word boundaries into one of the following symbols as appropiate.\n",
    "\n",
    "space\n",
    "tab\n",
    "vertical tab\n",
    "carriage return\n",
    "formfeed\n",
    "the null character\n",
    "\n",
    "The newline character is used to delimit lines of text. In particular, the EOS token is appended to a line of text if a newline character is encountered. The only exception is if the number of tokens exceeds the MAX_LINE_SIZE constant as defined in the Dictionary header. This means if you have text that is not separate by newlines, such as the fil9 dataset, it will be broken into chunks with MAX_LINE_SIZE of tokens and the EOS token is not appended.\n",
    "\n",
    "The length of a token is the number of UTF-8 characters by considering the leading two bits of a byte to identify subsequent bytes of a multi-byte sequence. Knowing this is especially important when choosing the minimum and maximum length of subwords. Further, the EOS token (as specified in the Dictionary header) is considered a character and will not be broken into subwords.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ ./fasttext supervised\n",
    "Empty input or output path.\n",
    "\n",
    "The following arguments are mandatory:\n",
    "  -input              training file path\n",
    "  -output             output file path\n",
    "\n",
    "The following arguments are optional:\n",
    "  -verbose            verbosity level [2]\n",
    "\n",
    "The following arguments for the dictionary are optional:\n",
    "  -minCount           minimal number of word occurrences [1]\n",
    "  -minCountLabel      minimal number of label occurrences [0]\n",
    "  -wordNgrams         max length of word ngram [1]\n",
    "  -bucket             number of buckets [2000000]\n",
    "  -minn               min length of char ngram [0]\n",
    "  -maxn               max length of char ngram [0]\n",
    "  -t                  sampling threshold [0.0001]\n",
    "  -label              labels prefix [__label__]\n",
    "\n",
    "The following arguments for training are optional:\n",
    "  -lr                 learning rate [0.1]\n",
    "  -lrUpdateRate       change the rate of updates for the learning rate [100]\n",
    "  -dim                size of word vectors [100]\n",
    "  -ws                 size of the context window [5]\n",
    "  -epoch              number of epochs [5]\n",
    "  -neg                number of negatives sampled [5]\n",
    "  -loss               loss function {ns, hs, softmax} [softmax]\n",
    "  -thread             number of threads [12]\n",
    "  -pretrainedVectors  pretrained word vectors for supervised learning []\n",
    "  -saveOutput         whether output params should be saved [0]\n",
    "\n",
    "The following arguments for quantization are optional:\n",
    "  -cutoff             number of words and ngrams to retain [0]\n",
    "  -retrain            finetune embeddings if a cutoff is applied [0]\n",
    "  -qnorm              quantizing the norm separately [0]\n",
    "  -qout               quantizing the classifier [0]\n",
    "  -dsub               size of each sub-vector [2]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
